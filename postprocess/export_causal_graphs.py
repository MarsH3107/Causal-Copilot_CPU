import json
import numpy as np
import pandas as pd
import os

def export_causal_graphs(global_state, output_dir=None):
    """
    å¯¼å‡ºåŸå§‹(converted)å’Œä¼˜åŒ–å(revised)çš„å› æœå›¾ä¸ºJSONå’ŒCSVæ ¼å¼
    
    å‚æ•°:
        global_state: å…¨å±€çŠ¶æ€å¯¹è±¡
        output_dir: è¾“å‡ºç›®å½•,é»˜è®¤ä½¿ç”¨ global_state.user_data.output_graph_dir
    """
    if output_dir is None:
        output_dir = global_state.user_data.output_graph_dir
    
    # è·å–å˜é‡å
    columns = global_state.user_data.processed_data.columns.tolist()
    
    # 1. å¯¼å‡ºåŸå§‹å› æœå›¾ (converted_graph)
    converted_graph = global_state.results.converted_graph
    export_single_graph(converted_graph, columns, output_dir, prefix="original")
    
    # 2. å¯¼å‡ºä¼˜åŒ–åçš„å› æœå›¾ (revised_graph) - å¦‚æœå­˜åœ¨
    if hasattr(global_state.results, 'revised_graph') and global_state.results.revised_graph is not None:
        revised_graph = global_state.results.revised_graph
        export_single_graph(revised_graph, columns, output_dir, prefix="revised")
        print(f"âœ… Revised graph exported")
    
    # 3. å¯¼å‡ºBootstrapæ¦‚ç‡çŸ©é˜µ - å¦‚æœå­˜åœ¨
    if hasattr(global_state.results, 'bootstrap_probability') and global_state.results.bootstrap_probability is not None:
        bootstrap_prob = global_state.results.bootstrap_probability
        np.save(os.path.join(output_dir, 'bootstrap_probability.npy'), bootstrap_prob)
        print(f"âœ… Bootstrap probability saved to: bootstrap_probability.npy")
    
    print(f"\nğŸ“ All files saved to: {output_dir}")


def export_single_graph(graph, columns, output_dir, prefix="original"):
    """
    å¯¼å‡ºå•ä¸ªå› æœå›¾ä¸ºå¤šç§æ ¼å¼
    
    å‚æ•°:
        graph: é‚»æ¥çŸ©é˜µ (np.ndarray)
        columns: å˜é‡ååˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        prefix: æ–‡ä»¶åå‰ç¼€ (original/revised)
    """
    edge_types = {
        0: 'none',
        1: 'directed (->)',
        2: 'undirected (-)',
        3: 'bidirected (<->)',
        4: 'half_directed (o->)',
        5: 'half_undirected (o-)',
        6: 'no_edge (o-o)',
        7: 'correlated (---)'
    }
    
    # === æ ¼å¼1: å®Œæ•´é‚»æ¥çŸ©é˜µ JSON ===
    adjacency_dict = {
        'variables': columns,
        'adjacency_matrix': graph.tolist(),
        'edge_types': edge_types,
        'description': 'Matrix[i,j] represents edge from j to i'
    }
    json_path = os.path.join(output_dir, f'{prefix}_adjacency_matrix.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(adjacency_dict, f, indent=2, ensure_ascii=False)
    print(f"âœ… {prefix} adjacency matrix saved to: {prefix}_adjacency_matrix.json")
    
    # === æ ¼å¼2: NumPyæ ¼å¼ (æ–¹ä¾¿Pythonè¯»å–) ===
    npy_path = os.path.join(output_dir, f'{prefix}_adjacency_matrix.npy')
    np.save(npy_path, graph)
    print(f"âœ… {prefix} numpy array saved to: {prefix}_adjacency_matrix.npy")
    
    # === æ ¼å¼3: è¾¹åˆ—è¡¨ JSON (æ›´ç›´è§‚) ===
    edge_list = []
    for i in range(len(columns)):
        for j in range(len(columns)):
            if graph[i, j] != 0:  # å­˜åœ¨è¾¹
                edge_list.append({
                    'source': columns[j],      # jæ˜¯æº
                    'target': columns[i],      # iæ˜¯ç›®æ ‡
                    'type': edge_types[graph[i, j]],
                    'code': int(graph[i, j])
                })
    
    edge_list_dict = {
        'edges': edge_list,
        'edge_count': len(edge_list),
        'node_count': len(columns),
        'edge_types': edge_types
    }
    edge_json_path = os.path.join(output_dir, f'{prefix}_edge_list.json')
    with open(edge_json_path, 'w', encoding='utf-8') as f:
        json.dump(edge_list_dict, f, indent=2, ensure_ascii=False)
    print(f"âœ… {prefix} edge list saved to: {prefix}_edge_list.json")
    
    # === æ ¼å¼4: CSVæ ¼å¼ (Excelå¯ç›´æ¥æ‰“å¼€) ===
    # 4.1 å®Œæ•´é‚»æ¥çŸ©é˜µCSV
    df_adj = pd.DataFrame(graph, index=columns, columns=columns)
    csv_path = os.path.join(output_dir, f'{prefix}_adjacency_matrix.csv')
    df_adj.to_csv(csv_path)
    print(f"âœ… {prefix} adjacency CSV saved to: {prefix}_adjacency_matrix.csv")
    
    # 4.2 è¾¹åˆ—è¡¨CSV
    if edge_list:
        df_edges = pd.DataFrame(edge_list)
        edge_csv_path = os.path.join(output_dir, f'{prefix}_edge_list.csv')
        df_edges.to_csv(edge_csv_path, index=False)
        print(f"âœ… {prefix} edge list CSV saved to: {prefix}_edge_list.csv")


def export_specific_relationships(global_state, source_vars, target_vars, output_dir=None):
    """
    å¯¼å‡ºç‰¹å®šå˜é‡ä¹‹é—´çš„å› æœå…³ç³» (ä¾‹å¦‚: æ¶æ„å‚æ•° -> æ€§èƒ½æŒ‡æ ‡)
    
    å‚æ•°:
        global_state: å…¨å±€çŠ¶æ€
        source_vars: æºå˜é‡åˆ—è¡¨ (ä¾‹å¦‚å‰22ä¸ªæ¶æ„å‚æ•°)
        target_vars: ç›®æ ‡å˜é‡åˆ—è¡¨ (ä¾‹å¦‚å4ä¸ªæ€§èƒ½æŒ‡æ ‡)
        output_dir: è¾“å‡ºç›®å½•
    """
    if output_dir is None:
        output_dir = global_state.user_data.output_graph_dir
    
    columns = global_state.user_data.processed_data.columns
    converted_graph = global_state.results.converted_graph
    
    # è·å–ç´¢å¼•
    source_indices = [columns.get_loc(var) for var in source_vars if var in columns]
    target_indices = [columns.get_loc(var) for var in target_vars if var in columns]
    
    # æå–å­å›¾
    relationships = []
    for src_idx in source_indices:
        for tgt_idx in target_indices:
            if converted_graph[tgt_idx, src_idx] != 0:  # src -> tgt
                relationships.append({
                    'source': columns[src_idx],
                    'target': columns[tgt_idx],
                    'type': get_edge_type_name(converted_graph[tgt_idx, src_idx]),
                    'code': int(converted_graph[tgt_idx, src_idx]),
                    'version': 'original'
                })
    
    # å¦‚æœæœ‰revisedç‰ˆæœ¬,ä¹ŸåŠ å…¥
    if hasattr(global_state.results, 'revised_graph') and global_state.results.revised_graph is not None:
        revised_graph = global_state.results.revised_graph
        for src_idx in source_indices:
            for tgt_idx in target_indices:
                if revised_graph[tgt_idx, src_idx] != 0:
                    relationships.append({
                        'source': columns[src_idx],
                        'target': columns[tgt_idx],
                        'type': get_edge_type_name(revised_graph[tgt_idx, src_idx]),
                        'code': int(revised_graph[tgt_idx, src_idx]),
                        'version': 'revised'
                    })
    
    # ä¿å­˜ä¸ºCSV
    df = pd.DataFrame(relationships)
    csv_path = os.path.join(output_dir, 'specific_causal_relationships.csv')
    df.to_csv(csv_path, index=False)
    print(f"\nâœ… Specific relationships saved to: specific_causal_relationships.csv")
    print(f"ğŸ“Š Found {len(relationships)} causal edges")
    
    # ä¿å­˜ä¸ºJSON
    json_path = os.path.join(output_dir, 'specific_causal_relationships.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump({'relationships': relationships}, f, indent=2, ensure_ascii=False)
    
    return df


def get_edge_type_name(code):
    """è·å–è¾¹ç±»å‹çš„åç§°"""
    edge_types = {
        0: 'none',
        1: 'directed',
        2: 'undirected',
        3: 'bidirected',
        4: 'half_directed',
        5: 'half_undirected',
        6: 'no_edge',
        7: 'correlated'
    }
    return edge_types.get(code, 'unknown')


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
if __name__ == "__main__":
    # åœ¨ main.py çš„æœ€åæ·»åŠ è¿™äº›è°ƒç”¨:
    
    # 1. å¯¼å‡ºæ‰€æœ‰å› æœå›¾
    export_causal_graphs(global_state)
    
    # 2. å¯¼å‡ºç‰¹å®šå…³ç³» (æ¶æ„å‚æ•° -> æ€§èƒ½æŒ‡æ ‡)
    # æ–¹å¼1: æŒ‰åˆ—ä½ç½®åˆ’åˆ† (æ¨è-çµæ´»)
    n_arch_params = 22  # å‰22åˆ—æ˜¯æ¶æ„å‚æ•°
    arch_params = global_state.user_data.processed_data.columns[:n_arch_params].tolist()
    metrics = global_state.user_data.processed_data.columns[n_arch_params:].tolist()
    
    # æ–¹å¼2: æ‰‹åŠ¨æŒ‡å®šåˆ—å (å¦‚æœä½ ç¡®å®šåˆ—å)
    # metrics = ['CPI', 'flush', 'ICacheMiss', 'DCacheMiss']
    
    # æ–¹å¼3: æ ¹æ®å…³é”®å­—è‡ªåŠ¨è¯†åˆ«
    # metrics = [col for col in columns if any(keyword in col.lower() 
    #            for keyword in ['cpi', 'miss', 'flush', 'cache'])]
    
    export_specific_relationships(
        global_state, 
        source_vars=arch_params,
        target_vars=metrics
    )
    
    print(f"\nâœ… Exported relationships:")
    print(f"   - Source variables (arch params): {len(arch_params)}")
    print(f"   - Target variables (metrics): {metrics}")